{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Eh6fZszEB61o","lubHVlG3KP59","K0wyHXhxSTma","k6Z4TYrQZPTU","Xnm0kh2PtLYG","eNZQlmp4FX3d","lEzaVNAIKb7d","_q70MfaoWcag"],"authorship_tag":"ABX9TyMQ03y1U8d9qXSLLwtYqalx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###  Things to install for the process"],"metadata":{"id":"IGzM0ggeB0Yc"}},{"cell_type":"code","source":["#Things needed to download the video\n","!pip install --upgrade pytubefix\n","!pip show pytube\n","\n","# Library for audio to text\n","!pip install openai-whisper\n","\n","# Library for scenedetection\n","!pip install scenedetect\n","!pip install pytubefix\n","\n","# Library for extracting the metadata\n","!pip install tinytag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"cNjThcUWAZLP","executionInfo":{"status":"ok","timestamp":1760117475665,"user_tz":-330,"elapsed":41396,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"a3072bf3-d399-495b-bf41-c303391b1c83"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytubefix\n","  Downloading pytubefix-10.0.0-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: aiohttp>=3.12.13 in /usr/local/lib/python3.12/dist-packages (from pytubefix) (3.13.0)\n","Collecting nodejs-wheel-binaries>=22.20.0 (from pytubefix)\n","  Downloading nodejs_wheel_binaries-22.20.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.22.0)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.12.13->pytubefix) (4.15.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.10)\n","Downloading pytubefix-10.0.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nodejs_wheel_binaries-22.20.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nodejs-wheel-binaries, pytubefix\n","Successfully installed nodejs-wheel-binaries-22.20.0 pytubefix-10.0.0\n","\u001b[33mWARNING: Package(s) not found: pytube\u001b[0m\u001b[33m\n","\u001b[0mCollecting openai-whisper\n","  Downloading openai_whisper-20250625.tar.gz (803 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=eb3843dea0f0073bdfac7d40e741ebfb8e98e70f60039b8917e36e2ba18db1b5\n","  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","Successfully installed openai-whisper-20250625\n","Collecting scenedetect\n","  Downloading scenedetect-0.6.7.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting click<8.3.0,~=8.0 (from scenedetect)\n","  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scenedetect) (2.0.2)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.67.1)\n","Downloading scenedetect-0.6.7.1-py3-none-any.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: click, scenedetect\n","  Attempting uninstall: click\n","    Found existing installation: click 8.3.0\n","    Uninstalling click-8.3.0:\n","      Successfully uninstalled click-8.3.0\n","Successfully installed click-8.2.1 scenedetect-0.6.7.1\n","Collecting tinytag\n","  Downloading tinytag-2.1.2-py3-none-any.whl.metadata (19 kB)\n","Downloading tinytag-2.1.2-py3-none-any.whl (31 kB)\n","Installing collected packages: tinytag\n","Successfully installed tinytag-2.1.2\n"]}]},{"cell_type":"markdown","source":["### Library for the video Application"],"metadata":{"id":"Eh6fZszEB61o"}},{"cell_type":"code","source":["# Library to import for the video download\n","from pytubefix import YouTube\n","from pytubefix.cli import on_progress\n","\n","# Library to import for the ContentDetection\n","from scenedetect import VideoManager, SceneManager\n","from scenedetect.detectors import ContentDetector\n","from moviepy.editor import VideoFileClip\n","\n","# Library for extracting the metadata\n","from tinytag import TinyTag\n","\n","# Library for extracting audio\n","import moviepy.editor as mp\n","\n","#Library needed for the scenedetection\n","import scenedetect\n","from scenedetect import open_video\n","from scenedetect import detect, ContentDetector, split_video_ffmpeg\n","\n","#Library for concating the video\n","from moviepy.editor import concatenate_videoclips"],"metadata":{"collapsed":true,"id":"wWkqR-M9A1L7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760117490846,"user_tz":-330,"elapsed":10135,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"f95c13d6-7ac4-4f1e-8bc7-0af8a4b7ad0e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n","  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n","/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n","  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n","/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n","  match = re.search('\\d+$', rotation_line)\n","/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n","  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n","WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n","  if event.key is 'enter':\n","\n"]}]},{"cell_type":"markdown","source":["#### Downloading Video is finished"],"metadata":{"id":"lubHVlG3KP59"}},{"cell_type":"code","source":["def download_youtube_video(filename=\"Sample.mp4\"):\n","    try:\n","        #Asking for the url\n","        url=str(input(\"Enter the url of the video\"))\n","\n","        # Create a YouTube object\n","        yt = YouTube(url)\n","\n","        # Get the Video\n","        stream = yt.streams.filter(file_extension=\"mp4\", progressive=True).first()\n","\n","        # Download the video with a specific filename (if provided)\n","        if filename:\n","            downloaded_file = stream.download(filename=filename)\n","        else:\n","            downloaded_file = stream.download()\n","\n","        # Print the name of the downloaded file\n","        print(f\"Video downloaded successfully: {downloaded_file}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","    return downloaded_file"],"metadata":{"id":"8pzcxdYXF19z","executionInfo":{"status":"ok","timestamp":1760117490895,"user_tz":-330,"elapsed":28,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x=download_youtube_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JaWM2BqGVzE","executionInfo":{"status":"ok","timestamp":1760027673908,"user_tz":-330,"elapsed":4101,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"a37e6f37-6896-4931-c7cd-1a2be9b4ddba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the url of the videohttps://youtu.be/eNvUS-6PTbs?si=Rl5a-j1y2ugo6A1n\n","Video downloaded successfully: /content/Sample.mp4\n"]}]},{"cell_type":"markdown","source":["### Extracted subtitle from the yt.video"],"metadata":{"id":"K0wyHXhxSTma"}},{"cell_type":"code","source":["from youtube_transcript_api import YouTubeTranscriptApi\n","from urllib.parse import urlparse, parse_qs\n","import pandas as pd"],"metadata":{"id":"ffSfyMg3YTjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_video_id(url:str):\n","  parsed=urlparse(url)\n","  if parsed.hostname in {\"www.youtube.com\",\"youtube.com\"}:\n","    qs=parse_qs(parsed.query)\n","    if \"v\" in qs:\n","      return qs[\"v\"][0]\n","  return parsed.path.lstrip(\"/\")"],"metadata":{"id":"dK1MzdiQYPYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_sub(url:str):\n","  \"\"\"\n","  url : Enter the url of the video you need to extract\n","\n","\n","  Enter the Url and the function will try to get the\n","  subtitle of the video and the timestamp of the subtitle,\n","  Create a dataframe out of it\"\"\"\n","\n","  video_id=extract_video_id(url)\n","  ytt_api=YouTubeTranscriptApi()\n","  subtitle=ytt_api.fetch(video_id)\n","  data =[{\"text\": s.text, \"start\": s.start, \"duration\": s.duration} for s in subtitle.snippets]\n","  dataframe=pd.DataFrame(data)\n","  return dataframe"],"metadata":{"id":"_jXUCUwdVks5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data=extract_sub(url=\"https://www.youtube.com/watch?v=U_v2cnTav7Y\")"],"metadata":{"id":"yzsDG7FQYadL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"QCFiaPgYYiyZ","executionInfo":{"status":"ok","timestamp":1760020297334,"user_tz":-330,"elapsed":109,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"ff2e32f9-5e89-4190-e4bb-bb693aae06fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        text   start  duration\n","0        This is the OnePlus 15. And I'll be    0.08     4.000\n","1   honest with you guys, OnePlus might fall    1.92     6.919\n","2   short against the competition this time.    4.08     4.759\n","3                                    [Music]   18.98     3.289\n","4      So, it's coming with this OnePlus 13S   23.60     4.160\n","..                                       ...     ...       ...\n","58    days. Thanks so much for watching. Let  175.20     3.280\n","59      me know your thoughts in the comment  177.04     3.760\n","60   section below and I'll meet you guys in  178.48     4.560\n","61     the next one. Like, share, subscribe,  180.80     5.719\n","62                            and peace out.  183.04     3.479\n","\n","[63 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-cbc31ece-5223-462c-bfcb-283d02ed3378\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>start</th>\n","      <th>duration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This is the OnePlus 15. And I'll be</td>\n","      <td>0.08</td>\n","      <td>4.000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>honest with you guys, OnePlus might fall</td>\n","      <td>1.92</td>\n","      <td>6.919</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>short against the competition this time.</td>\n","      <td>4.08</td>\n","      <td>4.759</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[Music]</td>\n","      <td>18.98</td>\n","      <td>3.289</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>So, it's coming with this OnePlus 13S</td>\n","      <td>23.60</td>\n","      <td>4.160</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>days. Thanks so much for watching. Let</td>\n","      <td>175.20</td>\n","      <td>3.280</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>me know your thoughts in the comment</td>\n","      <td>177.04</td>\n","      <td>3.760</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>section below and I'll meet you guys in</td>\n","      <td>178.48</td>\n","      <td>4.560</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>the next one. Like, share, subscribe,</td>\n","      <td>180.80</td>\n","      <td>5.719</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>and peace out.</td>\n","      <td>183.04</td>\n","      <td>3.479</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>63 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbc31ece-5223-462c-bfcb-283d02ed3378')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cbc31ece-5223-462c-bfcb-283d02ed3378 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cbc31ece-5223-462c-bfcb-283d02ed3378');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b1edf1e5-b2f2-4906-b33b-d34606d53e50\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1edf1e5-b2f2-4906-b33b-d34606d53e50')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b1edf1e5-b2f2-4906-b33b-d34606d53e50 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_752bba87-a1e5-46db-bbee-ac3d8d204686\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_752bba87-a1e5-46db-bbee-ac3d8d204686 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62,\n        \"samples\": [\n          \"those who doesn't want to spend that\",\n          \"this is OnePlus 15 coming soon in a few\",\n          \"This is the OnePlus 15. And I'll be\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.9092384755292,\n        \"min\": 0.08,\n        \"max\": 183.04,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          180.8,\n          172.879,\n          0.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1297622461026453,\n        \"min\": 3.0,\n        \"max\": 8.119,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          5.761,\n          4.64,\n          4.161\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Extracting the audio with the timestamp"],"metadata":{"id":"k6Z4TYrQZPTU"}},{"cell_type":"code","source":["!pip install openai-whisper moviepy\n"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"8FzsQHwJYnTm","executionInfo":{"status":"ok","timestamp":1760020506154,"user_tz":-330,"elapsed":14731,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"d65065ed-0f68-4175-fb89-ca61ecdc5de2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai-whisper\n","  Downloading openai_whisper-20250625.tar.gz (803 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m768.0/803.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.8.3)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=52b3a3a22358024e2fd2a744184b7673f5a547e27933ba3e2aaa3ca27c270acd\n","  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","Successfully installed openai-whisper-20250625\n"]}]},{"cell_type":"code","source":["x=download_youtube_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbRQ3Nd7ZWt-","executionInfo":{"status":"ok","timestamp":1760020771884,"user_tz":-330,"elapsed":2586,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"9bf72e99-1907-4935-fc27-b3c61f0753a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the url of the videohttps://www.youtube.com/watch?v=U_v2cnTav7Y\\\n","Video downloaded successfully: /content/Sample.mp4\n"]}]},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip"],"metadata":{"id":"QXwY58gJaVRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["video = VideoFileClip(x)\n","video.audio.write_audiofile(\"audio.wav\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZXQQljHadk3","executionInfo":{"status":"ok","timestamp":1760027731774,"user_tz":-330,"elapsed":1957,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"4a23c566-f6a2-4a86-9ab4-e0b18778337b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in audio.wav\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n"]}]},{"cell_type":"code","source":["import whisper\n","\n","model = whisper.load_model(\"base\")\n","result = model.transcribe(\"audio.wav\", verbose=True)\n","print(result[\"segments\"])"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"MPRdh23jagOi","executionInfo":{"status":"ok","timestamp":1760020869569,"user_tz":-330,"elapsed":67561,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"a70ce838-fbb3-4f72-b5fc-3fc503593aa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 122MiB/s]\n","WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","\n"]},{"output_type":"stream","name":"stdout","text":["Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n","Detected language: English\n","[00:00.000 --> 00:02.720]  This C1 Plus 15, and I'll be honest with you guys,\n","[00:02.720 --> 00:06.720]  OnePlus might fall short against the competition this time.\n","[00:23.440 --> 00:27.120]  So it's coming with this OnePlus 30-ness kind of design language.\n","[00:27.120 --> 00:31.440]  Similar Squarish module containing triple cameras and a LED flash,\n","[00:31.440 --> 00:35.920]  but with a larger form factor at 6.7 inch or 6.8 inch I guess.\n","[00:40.160 --> 00:44.320]  OnePlus is using a boxy design with nano ceramic metal frame.\n","[00:44.320 --> 00:48.880]  Yeah, I kind of like this minimal finish, but when you compare it to a latest pixel,\n","[00:48.880 --> 00:55.040]  Samsung Ultra iPhone 17 or Xiaomi 17 lineup, it doesn't stand out cause of no\n","[00:55.040 --> 00:57.920]  less innovation in terms of the design.\n","[01:00.160 --> 01:03.040]  So a generic mid-range kind of design it is,\n","[01:03.920 --> 01:05.840]  not anything special.\n","[01:08.480 --> 01:11.440]  The rumored specifications however are decent.\n","[01:11.440 --> 01:15.280]  OnePlus is using a 165Hz high refresh rate,\n","[01:15.280 --> 01:20.400]  1.5K resolution display. They should have gone with a 1440p panel with\n","[01:20.400 --> 01:25.600]  120Hz refresh rate with anti-reflective coating on the top.\n","[01:25.600 --> 01:28.000]  That would have been the perfect combination.\n","[01:28.000 --> 01:31.760]  They are no too less side top and bottom bezel and it's a flat panel,\n","[01:31.760 --> 01:35.600]  so no curve edges. Something I'm gonna miss for sure.\n","[01:36.560 --> 01:42.080]  The highlight of this device is Callgom 8 Elite Gen 5 fish no doubt is powerful and power\n","[01:42.080 --> 01:49.200]  efficient. This paired with a 7000 plus mh battery with 120 watts of wired and 50 watts\n","[01:49.200 --> 01:54.800]  wireless and oxygen-less 16 based on a 16. Rest of the specs are fast storage,\n","[01:54.800 --> 02:02.000]  DDR5X RAM, ultrasonic fingerprint scanner, and IP68 plus IP69 certification.\n","[02:06.400 --> 02:11.200]  They are triple cameras of 50MP each, 3x telephoto shooter.\n","[02:11.200 --> 02:15.600]  Now OnePlus is using detailed max engine for the color signs,\n","[02:15.600 --> 02:20.240]  so they are done with the Heselbett partnership and they say this new technology is gonna help\n","[02:20.240 --> 02:25.920]  capture real life colors and details. Here are some camera samples shared by OnePlus\n","[02:25.920 --> 02:28.080]  and they do look promising.\n","[02:33.600 --> 02:38.480]  So again decent set of specifications but not anything special, it's like for those who\n","[02:38.480 --> 02:43.760]  doesn't want to spend that much and one an 8 Elite Gen 5 device with powerful specs,\n","[02:43.760 --> 02:46.880]  mediocre flagship display and no too less innovation.\n","[02:48.480 --> 02:54.560]  C1 Plus might be holding back for a special Pro flagship but as of now this C1 Plus 15 coming soon\n","[02:54.560 --> 02:59.440]  in a few days, thanks so much for watching, let me know your thoughts in the comments section below\n","[02:59.440 --> 03:03.760]  and I'll meet you guys in the next one, like share, subscribe and peace out.\n","[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 2.72, 'text': \" This C1 Plus 15, and I'll be honest with you guys,\", 'tokens': [50364, 639, 383, 16, 7721, 2119, 11, 293, 286, 603, 312, 3245, 365, 291, 1074, 11, 50500], 'temperature': 0.0, 'avg_logprob': -0.3906141519546509, 'compression_ratio': 1.2661870503597121, 'no_speech_prob': 0.007376288063824177}, {'id': 1, 'seek': 0, 'start': 2.72, 'end': 6.72, 'text': ' OnePlus might fall short against the competition this time.', 'tokens': [50500, 41352, 1062, 2100, 2099, 1970, 264, 6211, 341, 565, 13, 50700], 'temperature': 0.0, 'avg_logprob': -0.3906141519546509, 'compression_ratio': 1.2661870503597121, 'no_speech_prob': 0.007376288063824177}, {'id': 2, 'seek': 0, 'start': 23.44, 'end': 27.12, 'text': \" So it's coming with this OnePlus 30-ness kind of design language.\", 'tokens': [51536, 407, 309, 311, 1348, 365, 341, 41352, 2217, 12, 1287, 733, 295, 1715, 2856, 13, 51720], 'temperature': 0.0, 'avg_logprob': -0.3906141519546509, 'compression_ratio': 1.2661870503597121, 'no_speech_prob': 0.007376288063824177}, {'id': 3, 'seek': 2712, 'start': 27.12, 'end': 31.44, 'text': ' Similar Squarish module containing triple cameras and a LED flash,', 'tokens': [50364, 10905, 8683, 289, 742, 10088, 19273, 15508, 8622, 293, 257, 11261, 7319, 11, 50580], 'temperature': 0.0, 'avg_logprob': -0.22778738305923787, 'compression_ratio': 1.4448979591836735, 'no_speech_prob': 0.01103571243584156}, {'id': 4, 'seek': 2712, 'start': 31.44, 'end': 35.92, 'text': ' but with a larger form factor at 6.7 inch or 6.8 inch I guess.', 'tokens': [50580, 457, 365, 257, 4833, 1254, 5952, 412, 1386, 13, 22, 7227, 420, 1386, 13, 23, 7227, 286, 2041, 13, 50804], 'temperature': 0.0, 'avg_logprob': -0.22778738305923787, 'compression_ratio': 1.4448979591836735, 'no_speech_prob': 0.01103571243584156}, {'id': 5, 'seek': 2712, 'start': 40.160000000000004, 'end': 44.32, 'text': ' OnePlus is using a boxy design with nano ceramic metal frame.', 'tokens': [51016, 41352, 307, 1228, 257, 2424, 88, 1715, 365, 30129, 29996, 5760, 3920, 13, 51224], 'temperature': 0.0, 'avg_logprob': -0.22778738305923787, 'compression_ratio': 1.4448979591836735, 'no_speech_prob': 0.01103571243584156}, {'id': 6, 'seek': 2712, 'start': 44.32, 'end': 48.88, 'text': ' Yeah, I kind of like this minimal finish, but when you compare it to a latest pixel,', 'tokens': [51224, 865, 11, 286, 733, 295, 411, 341, 13206, 2413, 11, 457, 562, 291, 6794, 309, 281, 257, 6792, 19261, 11, 51452], 'temperature': 0.0, 'avg_logprob': -0.22778738305923787, 'compression_ratio': 1.4448979591836735, 'no_speech_prob': 0.01103571243584156}, {'id': 7, 'seek': 2712, 'start': 48.88, 'end': 55.040000000000006, 'text': \" Samsung Ultra iPhone 17 or Xiaomi 17 lineup, it doesn't stand out cause of no\", 'tokens': [51452, 13173, 20925, 7252, 3282, 420, 33806, 3282, 26461, 11, 309, 1177, 380, 1463, 484, 3082, 295, 572, 51760], 'temperature': 0.0, 'avg_logprob': -0.22778738305923787, 'compression_ratio': 1.4448979591836735, 'no_speech_prob': 0.01103571243584156}, {'id': 8, 'seek': 5504, 'start': 55.04, 'end': 57.92, 'text': ' less innovation in terms of the design.', 'tokens': [50364, 1570, 8504, 294, 2115, 295, 264, 1715, 13, 50508], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 9, 'seek': 5504, 'start': 60.16, 'end': 63.04, 'text': ' So a generic mid-range kind of design it is,', 'tokens': [50620, 407, 257, 19577, 2062, 12, 14521, 733, 295, 1715, 309, 307, 11, 50764], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 10, 'seek': 5504, 'start': 63.92, 'end': 65.84, 'text': ' not anything special.', 'tokens': [50808, 406, 1340, 2121, 13, 50904], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 11, 'seek': 5504, 'start': 68.48, 'end': 71.44, 'text': ' The rumored specifications however are decent.', 'tokens': [51036, 440, 8347, 2769, 29448, 4461, 366, 8681, 13, 51184], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 12, 'seek': 5504, 'start': 71.44, 'end': 75.28, 'text': ' OnePlus is using a 165Hz high refresh rate,', 'tokens': [51184, 41352, 307, 1228, 257, 3165, 20, 21409, 1090, 15134, 3314, 11, 51376], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 13, 'seek': 5504, 'start': 75.28, 'end': 80.4, 'text': ' 1.5K resolution display. They should have gone with a 1440p panel with', 'tokens': [51376, 502, 13, 20, 42, 8669, 4674, 13, 814, 820, 362, 2780, 365, 257, 3499, 5254, 79, 4831, 365, 51632], 'temperature': 0.0, 'avg_logprob': -0.24748486836751302, 'compression_ratio': 1.3958333333333333, 'no_speech_prob': 0.008271356113255024}, {'id': 14, 'seek': 8040, 'start': 80.4, 'end': 85.60000000000001, 'text': ' 120Hz refresh rate with anti-reflective coating on the top.', 'tokens': [50364, 10411, 21409, 15134, 3314, 365, 6061, 12, 33115, 1809, 488, 20163, 322, 264, 1192, 13, 50624], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 15, 'seek': 8040, 'start': 85.60000000000001, 'end': 88.0, 'text': ' That would have been the perfect combination.', 'tokens': [50624, 663, 576, 362, 668, 264, 2176, 6562, 13, 50744], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 16, 'seek': 8040, 'start': 88.0, 'end': 91.76, 'text': \" They are no too less side top and bottom bezel and it's a flat panel,\", 'tokens': [50744, 814, 366, 572, 886, 1570, 1252, 1192, 293, 2767, 37179, 293, 309, 311, 257, 4962, 4831, 11, 50932], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 17, 'seek': 8040, 'start': 91.76, 'end': 95.60000000000001, 'text': \" so no curve edges. Something I'm gonna miss for sure.\", 'tokens': [50932, 370, 572, 7605, 8819, 13, 6595, 286, 478, 799, 1713, 337, 988, 13, 51124], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 18, 'seek': 8040, 'start': 96.56, 'end': 102.08000000000001, 'text': ' The highlight of this device is Callgom 8 Elite Gen 5 fish no doubt is powerful and power', 'tokens': [51172, 440, 5078, 295, 341, 4302, 307, 7807, 70, 298, 1649, 34404, 3632, 1025, 3506, 572, 6385, 307, 4005, 293, 1347, 51448], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 19, 'seek': 8040, 'start': 102.08000000000001, 'end': 109.2, 'text': ' efficient. This paired with a 7000 plus mh battery with 120 watts of wired and 50 watts', 'tokens': [51448, 7148, 13, 639, 25699, 365, 257, 1614, 1360, 1804, 275, 71, 5809, 365, 10411, 31247, 295, 27415, 293, 2625, 31247, 51804], 'temperature': 0.0, 'avg_logprob': -0.2968982803487332, 'compression_ratio': 1.5358490566037737, 'no_speech_prob': 0.004286702256649733}, {'id': 20, 'seek': 10920, 'start': 109.2, 'end': 114.8, 'text': ' wireless and oxygen-less 16 based on a 16. Rest of the specs are fast storage,', 'tokens': [50364, 14720, 293, 9169, 12, 1832, 3165, 2361, 322, 257, 3165, 13, 13094, 295, 264, 27911, 366, 2370, 6725, 11, 50644], 'temperature': 0.0, 'avg_logprob': -0.32740605504889236, 'compression_ratio': 1.3446601941747574, 'no_speech_prob': 0.0034150455612689257}, {'id': 21, 'seek': 10920, 'start': 114.8, 'end': 122.0, 'text': ' DDR5X RAM, ultrasonic fingerprint scanner, and IP68 plus IP69 certification.', 'tokens': [50644, 49272, 20, 55, 14561, 11, 3725, 81, 39460, 30715, 30211, 11, 293, 8671, 27102, 1804, 8671, 30908, 21775, 13, 51004], 'temperature': 0.0, 'avg_logprob': -0.32740605504889236, 'compression_ratio': 1.3446601941747574, 'no_speech_prob': 0.0034150455612689257}, {'id': 22, 'seek': 10920, 'start': 126.4, 'end': 131.2, 'text': ' They are triple cameras of 50MP each, 3x telephoto shooter.', 'tokens': [51224, 814, 366, 15508, 8622, 295, 2625, 12224, 1184, 11, 805, 87, 4304, 950, 6738, 24680, 13, 51464], 'temperature': 0.0, 'avg_logprob': -0.32740605504889236, 'compression_ratio': 1.3446601941747574, 'no_speech_prob': 0.0034150455612689257}, {'id': 23, 'seek': 10920, 'start': 131.2, 'end': 135.6, 'text': ' Now OnePlus is using detailed max engine for the color signs,', 'tokens': [51464, 823, 41352, 307, 1228, 9942, 11469, 2848, 337, 264, 2017, 7880, 11, 51684], 'temperature': 0.0, 'avg_logprob': -0.32740605504889236, 'compression_ratio': 1.3446601941747574, 'no_speech_prob': 0.0034150455612689257}, {'id': 24, 'seek': 13560, 'start': 135.6, 'end': 140.23999999999998, 'text': ' so they are done with the Heselbett partnership and they say this new technology is gonna help', 'tokens': [50364, 370, 436, 366, 1096, 365, 264, 389, 279, 338, 65, 3093, 9982, 293, 436, 584, 341, 777, 2899, 307, 799, 854, 50596], 'temperature': 0.0, 'avg_logprob': -0.29125669728154724, 'compression_ratio': 1.4898989898989898, 'no_speech_prob': 0.0034118513576686382}, {'id': 25, 'seek': 13560, 'start': 140.23999999999998, 'end': 145.92, 'text': ' capture real life colors and details. Here are some camera samples shared by OnePlus', 'tokens': [50596, 7983, 957, 993, 4577, 293, 4365, 13, 1692, 366, 512, 2799, 10938, 5507, 538, 41352, 50880], 'temperature': 0.0, 'avg_logprob': -0.29125669728154724, 'compression_ratio': 1.4898989898989898, 'no_speech_prob': 0.0034118513576686382}, {'id': 26, 'seek': 13560, 'start': 145.92, 'end': 148.07999999999998, 'text': ' and they do look promising.', 'tokens': [50880, 293, 436, 360, 574, 20257, 13, 50988], 'temperature': 0.0, 'avg_logprob': -0.29125669728154724, 'compression_ratio': 1.4898989898989898, 'no_speech_prob': 0.0034118513576686382}, {'id': 27, 'seek': 13560, 'start': 153.6, 'end': 158.48, 'text': \" So again decent set of specifications but not anything special, it's like for those who\", 'tokens': [51264, 407, 797, 8681, 992, 295, 29448, 457, 406, 1340, 2121, 11, 309, 311, 411, 337, 729, 567, 51508], 'temperature': 0.0, 'avg_logprob': -0.29125669728154724, 'compression_ratio': 1.4898989898989898, 'no_speech_prob': 0.0034118513576686382}, {'id': 28, 'seek': 15848, 'start': 158.48, 'end': 163.76, 'text': \" doesn't want to spend that much and one an 8 Elite Gen 5 device with powerful specs,\", 'tokens': [50364, 1177, 380, 528, 281, 3496, 300, 709, 293, 472, 364, 1649, 34404, 3632, 1025, 4302, 365, 4005, 27911, 11, 50628], 'temperature': 0.0, 'avg_logprob': -0.22852420806884766, 'compression_ratio': 1.556390977443609, 'no_speech_prob': 0.017563510686159134}, {'id': 29, 'seek': 15848, 'start': 163.76, 'end': 166.88, 'text': ' mediocre flagship display and no too less innovation.', 'tokens': [50628, 45415, 30400, 4674, 293, 572, 886, 1570, 8504, 13, 50784], 'temperature': 0.0, 'avg_logprob': -0.22852420806884766, 'compression_ratio': 1.556390977443609, 'no_speech_prob': 0.017563510686159134}, {'id': 30, 'seek': 15848, 'start': 168.48, 'end': 174.56, 'text': ' C1 Plus might be holding back for a special Pro flagship but as of now this C1 Plus 15 coming soon', 'tokens': [50864, 383, 16, 7721, 1062, 312, 5061, 646, 337, 257, 2121, 1705, 30400, 457, 382, 295, 586, 341, 383, 16, 7721, 2119, 1348, 2321, 51168], 'temperature': 0.0, 'avg_logprob': -0.22852420806884766, 'compression_ratio': 1.556390977443609, 'no_speech_prob': 0.017563510686159134}, {'id': 31, 'seek': 15848, 'start': 174.56, 'end': 179.44, 'text': ' in a few days, thanks so much for watching, let me know your thoughts in the comments section below', 'tokens': [51168, 294, 257, 1326, 1708, 11, 3231, 370, 709, 337, 1976, 11, 718, 385, 458, 428, 4598, 294, 264, 3053, 3541, 2507, 51412], 'temperature': 0.0, 'avg_logprob': -0.22852420806884766, 'compression_ratio': 1.556390977443609, 'no_speech_prob': 0.017563510686159134}, {'id': 32, 'seek': 15848, 'start': 179.44, 'end': 183.76, 'text': \" and I'll meet you guys in the next one, like share, subscribe and peace out.\", 'tokens': [51412, 293, 286, 603, 1677, 291, 1074, 294, 264, 958, 472, 11, 411, 2073, 11, 3022, 293, 4336, 484, 13, 51628], 'temperature': 0.0, 'avg_logprob': -0.22852420806884766, 'compression_ratio': 1.556390977443609, 'no_speech_prob': 0.017563510686159134}]\n"]}]},{"cell_type":"code","source":["with open(\"subtitles.srt\", \"w\") as f:\n","    for i, seg in enumerate(result[\"segments\"], 1):\n","        f.write(f\"{i}\\n\")\n","        f.write(f\"{seg['start']:.3f} --> {seg['end']:.3f}\\n\")\n","        f.write(f\"{seg['text']}\\n\\n\")\n"],"metadata":{"id":"QcWEUtEKaiis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming result[\"segments\"] is a list of dicts with 'start', 'end', and 'text'\n","segments = result[\"segments\"]\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(segments)\n","\n","# Display the table\n","print(df[['start', 'end', 'text']])\n"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"VuaG15k2a4Jl","executionInfo":{"status":"ok","timestamp":1760020945984,"user_tz":-330,"elapsed":148,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"a1f4b866-bf08-4a93-ad6f-d4fc2909cb5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     start     end                                               text\n","0     0.00    2.72   This C1 Plus 15, and I'll be honest with you ...\n","1     2.72    6.72   OnePlus might fall short against the competit...\n","2    23.44   27.12   So it's coming with this OnePlus 30-ness kind...\n","3    27.12   31.44   Similar Squarish module containing triple cam...\n","4    31.44   35.92   but with a larger form factor at 6.7 inch or ...\n","5    40.16   44.32   OnePlus is using a boxy design with nano cera...\n","6    44.32   48.88   Yeah, I kind of like this minimal finish, but...\n","7    48.88   55.04   Samsung Ultra iPhone 17 or Xiaomi 17 lineup, ...\n","8    55.04   57.92            less innovation in terms of the design.\n","9    60.16   63.04       So a generic mid-range kind of design it is,\n","10   63.92   65.84                              not anything special.\n","11   68.48   71.44     The rumored specifications however are decent.\n","12   71.44   75.28        OnePlus is using a 165Hz high refresh rate,\n","13   75.28   80.40   1.5K resolution display. They should have gon...\n","14   80.40   85.60   120Hz refresh rate with anti-reflective coati...\n","15   85.60   88.00      That would have been the perfect combination.\n","16   88.00   91.76   They are no too less side top and bottom beze...\n","17   91.76   95.60   so no curve edges. Something I'm gonna miss f...\n","18   96.56  102.08   The highlight of this device is Callgom 8 Eli...\n","19  102.08  109.20   efficient. This paired with a 7000 plus mh ba...\n","20  109.20  114.80   wireless and oxygen-less 16 based on a 16. Re...\n","21  114.80  122.00   DDR5X RAM, ultrasonic fingerprint scanner, an...\n","22  126.40  131.20   They are triple cameras of 50MP each, 3x tele...\n","23  131.20  135.60   Now OnePlus is using detailed max engine for ...\n","24  135.60  140.24   so they are done with the Heselbett partnersh...\n","25  140.24  145.92   capture real life colors and details. Here ar...\n","26  145.92  148.08                        and they do look promising.\n","27  153.60  158.48   So again decent set of specifications but not...\n","28  158.48  163.76   doesn't want to spend that much and one an 8 ...\n","29  163.76  166.88   mediocre flagship display and no too less inn...\n","30  168.48  174.56   C1 Plus might be holding back for a special P...\n","31  174.56  179.44   in a few days, thanks so much for watching, l...\n","32  179.44  183.76   and I'll meet you guys in the next one, like ...\n"]}]},{"cell_type":"code","source":["x=download_youtube_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoufTKlXdS8J","executionInfo":{"status":"ok","timestamp":1760021769233,"user_tz":-330,"elapsed":3199,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"fe93c4d8-cc76-4c06-9aac-504a7f46af78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the url of the videohttps://youtu.be/GJCj4lfraDc?si=Ca8hH7yQhpK1nyB3\n","Video downloaded successfully: /content/Sample.mp4\n"]}]},{"cell_type":"code","source":["extract_sub(\"https://youtu.be/GJCj4lfraDc?si=Ca8hH7yQhpK1nyB3\")"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"gnsUDbRSd4i1","executionInfo":{"status":"error","timestamp":1760021802531,"user_tz":-330,"elapsed":1218,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"a348d893-0f28-4da8-acee-d4b98205991a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TranscriptsDisabled","evalue":"\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=GJCj4lfraDc! This is most likely caused by:\n\nSubtitles are disabled for this video\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTranscriptsDisabled\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3792016067.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://youtu.be/GJCj4lfraDc?si=Ca8hH7yQhpK1nyB3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1824219863.py\u001b[0m in \u001b[0;36mextract_sub\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mvideo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_video_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mytt_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0msubtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytt_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnippets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id, languages, preserve_formatting)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[1;32m     70\u001b[0m         return (\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfind_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mMake\u001b[0m \u001b[0msure\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mactual\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mURL\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         )\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_innertube_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0minnertube_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_innertube_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnertube_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRequestBlocked\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             retries = (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_extract_captions_json\u001b[0;34m(self, innertube_data, video_id)\u001b[0m\n\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaptions_json\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"captionTracks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaptions_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTranscriptsDisabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcaptions_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTranscriptsDisabled\u001b[0m: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=GJCj4lfraDc! This is most likely caused by:\n\nSubtitles are disabled for this video\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!"]}]},{"cell_type":"markdown","source":["### Combine both to get any of one"],"metadata":{"id":"Xnm0kh2PtLYG"}},{"cell_type":"code","source":["def download_subtitle_or_transcribe(url,download_path):\n","  \"\"\" Try to download the subtitle else audio Transcription\"\"\"\n","  try:\n","    video_id=extract_video_id(url)\n","    ytt_api=YouTubeTranscriptApi()\n","    subtitle=ytt_api.fetch(video_id)\n","    data =[{\"text\": s.text, \"start\": s.start, \"duration\": s.duration} for s in subtitle.snippets]\n","    dataframe=pd.DataFrame(data)\n","    return dataframe\n","  except Exception as e:\n","    video = VideoFileClip(download_path)\n","    video.audio.write_audiofile(\"audio.wav\")\n","    model = whisper.load_model(\"base\")\n","    result = model.transcribe(\"audio.wav\", verbose=False)\n","    #print(result[\"segments\"])\n","    segments = result[\"segments\"]\n","    # Convert to DataFrame\n","    df = pd.DataFrame(segments)\n","    selected_df = df[['start', 'end', 'text']]\n","    # Display the table\n","    return selected_df\n"],"metadata":{"id":"e_M3MF6CeWhB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["download_subtitle_or_transcribe(url=\"https://youtu.be/eNvUS-6PTbs?si=Rl5a-j1y2ugo6A1n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"YJ-EFmu9siyY","executionInfo":{"status":"ok","timestamp":1760029101407,"user_tz":-330,"elapsed":45329,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"0819b41d-3fee-4abd-f434-9f38484f0e05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in audio.wav\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","\n"]},{"output_type":"stream","name":"stdout","text":["Detected language: English\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 19700/19704 [00:36<00:00, 545.89frames/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["    start    end                                               text\n","0     0.0   18.0                                              Music\n","1    18.0   22.0      Oh I can not explain every time it's the same\n","2    22.0   26.0          More I feel they're free to take my heart\n","3    26.0   31.0   I've been lonely too long, oh I can't be so s...\n","4    31.0   34.0         Take the chance for a man to take my heart\n","5    34.0   42.0      I need you soon, there's no time I'll ever go\n","6    42.0   47.0               Sherry Sherry Lady, go into a motion\n","7    47.0   51.0   Love is where you find it, in the sun to your...\n","8    51.0   55.0       I'm Sherry Sherry Lady, living in the motion\n","9    55.0   59.0   It's always like the first time, let me take ...\n","10   59.0   64.0   I'm Sherry Sherry Lady, like the first one to...\n","11   64.0   70.0   Take my heart and listen to your cherry cherr...\n","12   70.0   74.0      And don't you worry, it's gonna be a good day\n","13   74.0   77.0                                    Be a great star\n","14   81.0   96.0                                              Music\n","15   96.0  100.0          I get back down, all my work comes around\n","16  100.0  104.0         Who was right, who was wrong, I don't know\n","17  104.0  108.0   I've got pain in my heart, got a love in my soul\n","18  108.0  112.0                     Easy come but I think, easy go\n","19  112.0  120.0         I need you soon, all the times I'm so slow\n","20  120.0  124.0               Sherry Sherry Lady, go into a motion\n","21  124.0  128.0    Love is where you find it, listen to your heart\n","22  128.0  133.0       I'm Sherry Sherry Lady, living in the motion\n","23  133.0  137.0   It's always like the first time, let me take ...\n","24  137.0  141.0   I'm Sherry Sherry Lady, like the first one to...\n","25  141.0  147.0   Take my heart and listen to your cherry cherr...\n","26  147.0  151.0      And don't you worry, it's gonna be a good day\n","27  151.0  155.0                                    Be a great star\n","28  168.0  173.0   Sherry Sherry Lady, like the first one to follow\n","29  173.0  179.0   Take my heart and listen to your cherry cherr...\n","30  179.0  183.0      And don't you worry, it's gonna be a good day\n","31  183.0  185.0                                    Be a great star"],"text/html":["\n","  <div id=\"df-e22821b6-9551-4b4a-979d-1a072f26f9e3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>18.0</td>\n","      <td>Music</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18.0</td>\n","      <td>22.0</td>\n","      <td>Oh I can not explain every time it's the same</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.0</td>\n","      <td>26.0</td>\n","      <td>More I feel they're free to take my heart</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26.0</td>\n","      <td>31.0</td>\n","      <td>I've been lonely too long, oh I can't be so s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.0</td>\n","      <td>34.0</td>\n","      <td>Take the chance for a man to take my heart</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>34.0</td>\n","      <td>42.0</td>\n","      <td>I need you soon, there's no time I'll ever go</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>42.0</td>\n","      <td>47.0</td>\n","      <td>Sherry Sherry Lady, go into a motion</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>47.0</td>\n","      <td>51.0</td>\n","      <td>Love is where you find it, in the sun to your...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>51.0</td>\n","      <td>55.0</td>\n","      <td>I'm Sherry Sherry Lady, living in the motion</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>55.0</td>\n","      <td>59.0</td>\n","      <td>It's always like the first time, let me take ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>59.0</td>\n","      <td>64.0</td>\n","      <td>I'm Sherry Sherry Lady, like the first one to...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>64.0</td>\n","      <td>70.0</td>\n","      <td>Take my heart and listen to your cherry cherr...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>70.0</td>\n","      <td>74.0</td>\n","      <td>And don't you worry, it's gonna be a good day</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>74.0</td>\n","      <td>77.0</td>\n","      <td>Be a great star</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>81.0</td>\n","      <td>96.0</td>\n","      <td>Music</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>96.0</td>\n","      <td>100.0</td>\n","      <td>I get back down, all my work comes around</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>100.0</td>\n","      <td>104.0</td>\n","      <td>Who was right, who was wrong, I don't know</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>104.0</td>\n","      <td>108.0</td>\n","      <td>I've got pain in my heart, got a love in my soul</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>108.0</td>\n","      <td>112.0</td>\n","      <td>Easy come but I think, easy go</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>112.0</td>\n","      <td>120.0</td>\n","      <td>I need you soon, all the times I'm so slow</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>120.0</td>\n","      <td>124.0</td>\n","      <td>Sherry Sherry Lady, go into a motion</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>124.0</td>\n","      <td>128.0</td>\n","      <td>Love is where you find it, listen to your heart</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>128.0</td>\n","      <td>133.0</td>\n","      <td>I'm Sherry Sherry Lady, living in the motion</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>133.0</td>\n","      <td>137.0</td>\n","      <td>It's always like the first time, let me take ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>137.0</td>\n","      <td>141.0</td>\n","      <td>I'm Sherry Sherry Lady, like the first one to...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>141.0</td>\n","      <td>147.0</td>\n","      <td>Take my heart and listen to your cherry cherr...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>147.0</td>\n","      <td>151.0</td>\n","      <td>And don't you worry, it's gonna be a good day</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>151.0</td>\n","      <td>155.0</td>\n","      <td>Be a great star</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>168.0</td>\n","      <td>173.0</td>\n","      <td>Sherry Sherry Lady, like the first one to follow</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>173.0</td>\n","      <td>179.0</td>\n","      <td>Take my heart and listen to your cherry cherr...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>179.0</td>\n","      <td>183.0</td>\n","      <td>And don't you worry, it's gonna be a good day</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>183.0</td>\n","      <td>185.0</td>\n","      <td>Be a great star</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e22821b6-9551-4b4a-979d-1a072f26f9e3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e22821b6-9551-4b4a-979d-1a072f26f9e3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e22821b6-9551-4b4a-979d-1a072f26f9e3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-35a01b92-843f-460d-931b-a92798720c51\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35a01b92-843f-460d-931b-a92798720c51')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-35a01b92-843f-460d-931b-a92798720c51 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"download_subtitle_or_transcribe(url=\\\"https://youtu\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.488362765535484,\n        \"min\": 0.0,\n        \"max\": 183.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          173.0,\n          96.0,\n          137.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.63422064808845,\n        \"min\": 18.0,\n        \"max\": 185.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          179.0,\n          100.0,\n          141.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \" Music\",\n          \" Easy come but I think, easy go\",\n          \" Who was right, who was wrong, I don't know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["### calculating the entire time for running!!!"],"metadata":{"id":"eNZQlmp4FX3d"}},{"cell_type":"code","source":["!pip install mlflow"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"7GhGB5ZvwrmB","executionInfo":{"status":"ok","timestamp":1760026638079,"user_tz":-330,"elapsed":25441,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"4e797e9c-6858-4178-c603-3c2bfd449c22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mlflow\n","  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n","Collecting mlflow-skinny==3.4.0 (from mlflow)\n","  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n","Collecting mlflow-tracing==3.4.0 (from mlflow)\n","  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.5)\n","Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n","Collecting docker<8,>=4.0.0 (from mlflow)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting fastmcp<3,>=2.0.0 (from mlflow)\n","  Downloading fastmcp-2.12.4-py3-none-any.whl.metadata (19 kB)\n","Collecting graphene<4 (from mlflow)\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n","Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n","Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.2)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.43)\n","Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (8.2.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.1)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->mlflow)\n","  Downloading databricks_sdk-0.67.0-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.118.0)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.45)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (8.7.0)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n","Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n","Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (25.0)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (5.29.5)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (2.11.9)\n","Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.1.1)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (6.0.3)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (2.32.4)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.5.3)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (4.15.0)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.37.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow) (2.0.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n","Requirement already satisfied: authlib>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.6.4)\n","Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow)\n","  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n","Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow)\n","  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (0.28.1)\n","Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.15.0)\n","Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow)\n","  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n","Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow)\n","  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.11.0)\n","Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (13.9.4)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow) (2.23)\n","Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (25.3.0)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.17.0)\n","Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (2.38.0)\n","Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow) (0.48.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (4.0.12)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (0.16.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow) (3.23.0)\n","Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.4.1)\n","Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (4.25.1)\n","Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2.11.0)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.0.20)\n","Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (3.0.2)\n","Collecting isodate (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (10.8.0)\n","Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n","Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n","Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n","  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow) (0.58b0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.4.2)\n","Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (3.4.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (2.19.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.3.1)\n","Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (4.9.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.27.1)\n","Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (0.1.2)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.1.4)\n","Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n","  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n","Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.21.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.6.1)\n","Downloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastmcp-2.12.4-py3-none-any.whl (329 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading databricks_sdk-0.67.0-py3-none-any.whl (718 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n","Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n","Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n","Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n","Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n","Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n","Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n","Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n","Installing collected packages: parse, werkzeug, pathable, lazy-object-proxy, isodate, gunicorn, graphql-core, exceptiongroup, dnspython, jsonschema-path, graphql-relay, email-validator, docker, rich-rst, openapi-pydantic, graphene, databricks-sdk, openapi-schema-validator, cyclopts, openapi-spec-validator, mlflow-tracing, mlflow-skinny, openapi-core, fastmcp, mlflow\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 3.1.3\n","    Uninstalling Werkzeug-3.1.3:\n","      Successfully uninstalled Werkzeug-3.1.3\n","Successfully installed cyclopts-3.24.0 databricks-sdk-0.67.0 dnspython-2.8.0 docker-7.1.0 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.4 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 isodate-0.7.2 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 parse-1.20.2 pathable-0.4.4 rich-rst-1.3.1 werkzeug-3.1.1\n"]}]},{"cell_type":"code","source":["#Things needed to download the video\n","!pip install --upgrade pytubefix\n","!pip show pytube\n","# Library for audio to text\n","!pip install openai-whisper\n","# Library for scenedetection\n","!pip install scenedetect\n","# Library for extracting the metadata\n","!pip install tinytag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Q6Clu5HsLzH0","executionInfo":{"status":"ok","timestamp":1760033816092,"user_tz":-330,"elapsed":30409,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"faf3670c-72c2-4749-923e-a01a3715a714"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytubefix in /usr/local/lib/python3.12/dist-packages (10.0.0)\n","Requirement already satisfied: aiohttp>=3.12.13 in /usr/local/lib/python3.12/dist-packages (from pytubefix) (3.12.15)\n","Requirement already satisfied: nodejs-wheel-binaries>=22.20.0 in /usr/local/lib/python3.12/dist-packages (from pytubefix) (22.20.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.20.1)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.12.13->pytubefix) (4.15.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.10)\n","\u001b[33mWARNING: Package(s) not found: pytube\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n","Requirement already satisfied: scenedetect in /usr/local/lib/python3.12/dist-packages (0.6.7.1)\n","Requirement already satisfied: click<8.3.0,~=8.0 in /usr/local/lib/python3.12/dist-packages (from scenedetect) (8.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scenedetect) (2.0.2)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.67.1)\n","Requirement already satisfied: tinytag in /usr/local/lib/python3.12/dist-packages (2.1.2)\n"]}]},{"cell_type":"code","source":["import mlflow\n","import time"],"metadata":{"id":"vprq2knBwX71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Library to import for the video download\n","from pytubefix import YouTube\n","from pytubefix.cli import on_progress\n","\n","# Library to import for the ContentDetection\n","from scenedetect import VideoManager, SceneManager\n","from scenedetect.detectors import ContentDetector\n","from moviepy.editor import VideoFileClip\n","\n","# Library for extracting the metadata\n","from tinytag import TinyTag\n","\n","# Library for extracting audio\n","import moviepy.editor as mp\n","\n","#Library for concating the video\n","from moviepy.editor import concatenate_videoclips\n","\n","import whisper\n","import pandas as pd\n","import mlflow\n","import time\n","\n","from youtube_transcript_api import YouTubeTranscriptApi\n","from urllib.parse import urlparse, parse_qs\n","import pandas as pd"],"metadata":{"id":"_KR5YBY4L3IM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def download_youtube_video(filename=\"Sample.mp4\"):\n","    try:\n","        #Asking for the url\n","        url=\"https://youtu.be/eNvUS-6PTbs?si=Rl5a-j1y2ugo6A1n\"\n","\n","        # Create a YouTube object\n","        yt = YouTube(url)\n","\n","        # Get the Video\n","        stream = yt.streams.filter(file_extension=\"mp4\", progressive=True).first()\n","\n","        # Download the video with a specific filename (if provided)\n","        if filename:\n","            downloaded_file = stream.download(filename=filename)\n","        else:\n","            downloaded_file = stream.download()\n","\n","        # Print the name of the downloaded file\n","        print(f\"Video downloaded successfully: {downloaded_file}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","    return url, downloaded_file"],"metadata":{"id":"6LwEQdVN2-J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_video_id(url:str):\n","  parsed=urlparse(url)\n","  if parsed.hostname in {\"www.youtube.com\",\"youtube.com\"}:\n","    qs=parse_qs(parsed.query)\n","    if \"v\" in qs:\n","      return qs[\"v\"][0]\n","  return parsed.path.lstrip(\"/\")"],"metadata":{"id":"OhPzCjBfL_VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_sub(url:str):\n","  \"\"\"\n","  url : Enter the url of the video you need to extract\n","\n","\n","  Enter the Url and the function will try to get the\n","  subtitle of the video and the timestamp of the subtitle,\n","  Create a dataframe out of it\"\"\"\n","\n","  video_id=extract_video_id(url)\n","  ytt_api=YouTubeTranscriptApi()\n","  subtitle=ytt_api.fetch(video_id)\n","  data =[{\"text\": s.text, \"start\": s.start, \"duration\": s.duration} for s in subtitle.snippets]\n","  dataframe=pd.DataFrame(data)\n","  return dataframe"],"metadata":{"id":"VfQrQuTsMDDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import whisper\n","from pydub import AudioSegment"],"metadata":{"id":"lXtBOR0SM877"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def download_subtitle_or_transcribe(url,download_path):\n","  \"\"\" Try to download the subtitle else audio Transcription\"\"\"\n","  try:\n","    video_id=extract_video_id(url)\n","    ytt_api=YouTubeTranscriptApi()\n","    subtitle=ytt_api.fetch(video_id)\n","    data =[{\"text\": s.text, \"start\": s.start, \"duration\": s.duration} for s in subtitle.snippets]\n","    dataframe=pd.DataFrame(data)\n","    return dataframe\n","  except Exception as e:\n","    video = VideoFileClip(download_path)\n","    video.audio.write_audiofile(\"audio.wav\")\n","\n","    # Faster inference\n","    model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")\n","    segments, info = model.transcribe(\"audio.wav\", beam_size=5)\n","    segments = list(segments)\n","\n","\n","    df = pd.DataFrame(segments)\n","    selected_df = df[['start', 'end', 'text']]\n","    return print(selected_df)"],"metadata":{"id":"gaUsdBLc7Pqc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x,y=download_youtube_video()\n","download_subtitle_or_transcribe(url=x, download_path=y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"e9-oHBmEGu4I","executionInfo":{"status":"error","timestamp":1760035407606,"user_tz":-330,"elapsed":8318,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"097f9c68-0703-4be1-f203-b42e118d4d2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Video downloaded successfully: /content/Sample.mp4\n","MoviePy - Writing audio in audio.wav\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTranscriptsDisabled\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-880689601.py\u001b[0m in \u001b[0;36mdownload_subtitle_or_transcribe\u001b[0;34m(url, download_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mytt_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msubtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytt_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnippets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id, languages, preserve_formatting)\u001b[0m\n\u001b[1;32m     70\u001b[0m         return (\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfind_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0minnertube_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_innertube_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnertube_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRequestBlocked\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_extract_captions_json\u001b[0;34m(self, innertube_data, video_id)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaptions_json\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"captionTracks\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaptions_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTranscriptsDisabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTranscriptsDisabled\u001b[0m: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=eNvUS-6PTbs! This is most likely caused by:\n\nSubtitles are disabled for this video\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3383885187.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_youtube_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownload_subtitle_or_transcribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-880689601.py\u001b[0m in \u001b[0;36mdownload_subtitle_or_transcribe\u001b[0;34m(url, download_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Faster inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhisperModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"audio.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/faster_whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(self, audio, language, task, log_progress, beam_size, best_of, patience, length_penalty, repetition_penalty, no_repeat_ngram_size, temperature, compression_ratio_threshold, log_prob_threshold, no_speech_threshold, condition_on_previous_text, prompt_reset_on_temperature, initial_prompt, prefix, suppress_blank, suppress_tokens, without_timestamps, max_initial_timestamp, word_timestamps, prepend_punctuations, append_punctuations, multilingual, vad_filter, vad_parameters, max_new_tokens, chunk_length, clip_timestamps, hallucination_silence_threshold, hotwords, language_detection_threshold, language_detection_segments)\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mlanguage_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mall_language_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseek\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                     \u001b[0mlanguage_detection_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage_detection_segments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/faster_whisper/transcribe.py\u001b[0m in \u001b[0;36mdetect_language\u001b[0;34m(self, audio, features, vad_filter, vad_parameters, language_detection_segments, language_detection_threshold)\u001b[0m\n\u001b[1;32m   1791\u001b[0m         \u001b[0mdetected_language_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_max_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             encoder_output = self.encode(\n\u001b[0m\u001b[1;32m   1794\u001b[0m                 \u001b[0mpad_or_trim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_max_frames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/faster_whisper/transcribe.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ctranslate2_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     def generate_with_fallback(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["with mlflow.start_run(run_name=\"Using-faster-whisper\",description=\"audio trans\"):\n","  start_time=time.time()\n","  x,y=download_youtube_video()\n","  download_subtitle_or_transcribe(url=x, download_path=y)\n","  end_time=time.time()\n","  runtime=end_time - start_time\n","  mlflow.log_metric(\"runtime_seconds\", runtime)\n","\n","  print(f\"\\nTotal Runtime: {runtime:.4f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"eIWBFCfEIy9d","executionInfo":{"status":"ok","timestamp":1760035585114,"user_tz":-330,"elapsed":92746,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"1c89fabb-78c5-4eea-d8ec-8c5cbba54651"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Video downloaded successfully: /content/Sample.mp4\n","MoviePy - Writing audio in audio.wav\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","    start    end                                               text\n","0     0.0   18.0                                              Music\n","1    18.0   22.0      Oh, I cannot explain every time it's the same\n","2    22.0   26.0          More I feel they're free to take my heart\n","3    26.0   31.0   I've been lonely too long, oh, I can't be so ...\n","4    31.0   37.0   To change for a man to take my heart, I need ...\n","5    37.0   42.0                      There's no time, I'll ever go\n","6    42.0   47.0              Sherry, Sherry lady, go into a motion\n","7    47.0   51.0   Love is where you find it, in the sun to your...\n","8    51.0   55.0      I'm Sherry, Sherry lady, living in the motion\n","9    55.0   59.0   It's always like the first time, let me take ...\n","10   59.0   64.0      I'm Sherry, Sherry lady, one person to follow\n","11   64.0   70.0   Take my heart, listen to your Sherry, Sherry ...\n","12   70.0   74.0   It's always like the first time, let me take ...\n","13   74.0   78.0      I'm Sherry, Sherry lady, living in the motion\n","14   78.0   96.0                                              Music\n","15   96.0  100.0       I've got back down, all my work comes around\n","16  100.0  104.0         Who was right, who was wrong, I don't know\n","17  104.0  108.0   I've got pain in my heart, got a love in my soul\n","18  108.0  112.0                    Easy come, but I think, easy go\n","19  112.0  120.0        I need you soon, all the times I'm upstairs\n","20  120.0  124.0              Sherry, Sherry lady, go into a motion\n","21  124.0  129.0   Love is where you find it, in the sun to your...\n","22  129.0  133.0      I'm Sherry, Sherry lady, living in the motion\n","23  133.0  137.0   It's always like the first time, let me take ...\n","24  137.0  141.0      I'm Sherry, Sherry lady, one person to follow\n","25  141.0  147.0   Take my heart, listen to your Sherry, Sherry ...\n","26  147.0  153.0   It's always like the first time, let me take ...\n","27  153.0  157.0      I'm Sherry, Sherry lady, living in the motion\n","28  157.0  169.0                                              Music\n","29  169.0  173.0         Dare and Shalry lady, one person to follow\n","30  173.0  179.0   Take my heart, listen to your Sherry, Sherry ...\n","31  179.0  183.0   It's always like the first time, let me take ...\n","\n","Total Runtime: 92.6830 seconds\n"]}]},{"cell_type":"markdown","source":["### Model runtime ( audio trans )\n","\n","- Baseline model :- 48.7809 seconds\n","- UsingFFmpeg-Whisper1 :- 51.4701 seconds\n","- Direct Transcription :- 44.3696 seconds\n","- PyDub Whisper :- 45.2708 seconds\n","- Using faster-whisper :- 92.6830 seconds\n"],"metadata":{"id":"lEzaVNAIKb7d"}},{"cell_type":"code","source":["#!rm -rf /content/mlruns/0/47fe4283cdc744e9965d1b73cc852aea"],"metadata":{"id":"Nn0kartdLHcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Created the below function by chapgpt"],"metadata":{"id":"_q70MfaoWcag"}},{"cell_type":"code","source":["import os\n","import json\n","import yaml\n","import pandas as pd\n","\n","def parse_mlruns(mlruns_path=\"/content/mlruns\"):\n","    \"\"\"\n","    Parses the mlruns folder to create a table for analysis.\n","\n","    Args:\n","        mlruns_path (str): Path to the mlruns folder (default is \"/content/mlruns\").\n","\n","    Returns:\n","        pd.DataFrame: A DataFrame containing run details (run_id, experiment_id, metrics, params, etc.).\n","    \"\"\"\n","    runs_data = []\n","\n","    # Iterate through each experiment folder in mlruns\n","    for experiment_id in os.listdir(mlruns_path):\n","        experiment_path = os.path.join(mlruns_path, experiment_id)\n","        if not os.path.isdir(experiment_path):\n","            continue  # Skip non-directory files\n","\n","        # Iterate through each run folder inside the experiment\n","        for run_id in os.listdir(experiment_path):\n","            run_path = os.path.join(experiment_path, run_id)\n","            if not os.path.isdir(run_path):\n","                continue\n","\n","            run_data = {\"experiment_id\": experiment_id, \"run_id\": run_id}\n","\n","            # ---- Load meta.yaml ----\n","            meta_file = os.path.join(run_path, \"meta.yaml\")\n","            if os.path.exists(meta_file):\n","                with open(meta_file, \"r\") as f:\n","                    meta = yaml.safe_load(f)\n","                    if isinstance(meta, dict):\n","                        run_data.update(meta)\n","\n","            # ---- Load metrics ----\n","            metrics_dir = os.path.join(run_path, \"metrics\")\n","            if os.path.exists(metrics_dir):\n","                for metric_file in os.listdir(metrics_dir):\n","                    metric_path = os.path.join(metrics_dir, metric_file)\n","                    if os.path.isfile(metric_path):\n","                        with open(metric_path, \"r\") as f:\n","                            lines = f.readlines()\n","                            # Each metric file can contain multiple lines like: step, value, timestamp\n","                            last_line = lines[-1].strip().split()\n","                            if len(last_line) >= 2:\n","                                value = float(last_line[1])\n","                                run_data[metric_file] = value\n","\n","            # ---- Load params ----\n","            params_dir = os.path.join(run_path, \"params\")\n","            if os.path.exists(params_dir):\n","                for param_file in os.listdir(params_dir):\n","                    param_path = os.path.join(params_dir, param_file)\n","                    if os.path.isfile(param_path):\n","                        with open(param_path, \"r\") as f:\n","                            run_data[param_file] = f.read().strip()\n","\n","            # ---- Convert runtime from ms → seconds ----\n","            # Some MLflow meta.yaml files have \"end_time\" and \"start_time\" in milliseconds\n","            if \"start_time\" in run_data and \"end_time\" in run_data:\n","                try:\n","                    start = int(run_data[\"start_time\"])\n","                    end = int(run_data[\"end_time\"])\n","                    run_data[\"runtime_seconds\"] = round((end - start) / 1000, 3)\n","                except (ValueError, TypeError):\n","                    run_data[\"runtime_seconds\"] = None\n","\n","            runs_data.append(run_data)\n","\n","    # Convert to DataFrame\n","    if not runs_data:\n","        print(\"No runs found in:\", mlruns_path)\n","        return pd.DataFrame()\n","\n","    return pd.DataFrame(runs_data)\n"],"metadata":{"id":"0mFSsn5VTTTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parse_mlruns()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"I_6bB7UkU66v","executionInfo":{"status":"ok","timestamp":1760036380691,"user_tz":-330,"elapsed":75,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"f4631ad1-cab1-4707-ee48-55fc036f2137"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  experiment_id                            run_id  \\\n","0             0  d800b7be6b1f452a91a148aa24791355   \n","1             0  73bb2b8f2771466abe54459d26ecbc33   \n","2             0  33514a226b13465ca6a0f8dd11fdb7b7   \n","3             0  089cee2123d142f998815b93c0d2fbe9   \n","4             0  68674e4a677e4243a1018d4029a26603   \n","\n","                                        artifact_uri       end_time  \\\n","0  file:///content/mlruns/0/d800b7be6b1f452a91a14...  1760033890150   \n","1  file:///content/mlruns/0/73bb2b8f2771466abe544...  1760034750417   \n","2  file:///content/mlruns/0/33514a226b13465ca6a0f...  1760035583964   \n","3  file:///content/mlruns/0/089cee2123d142f998815...  1760034580533   \n","4  file:///content/mlruns/0/68674e4a677e4243a1018...  1760034396938   \n","\n","  entry_point_name lifecycle_stage              run_name source_name  \\\n","0                           active   Baseline-model_run1               \n","1                           active         PyDub-Whisper               \n","2                           active  Using-faster-whisper               \n","3                           active  Direct-Transcription               \n","4                           active  UsingFFmpeg-Whisper1               \n","\n","   source_type source_version     start_time  status tags user_id  \\\n","0            4                 1760033841519       3   []    root   \n","1            4                 1760034705123       3   []    root   \n","2            4                 1760035491268       3   []    root   \n","3            4                 1760034536151       3   []    root   \n","4            4                 1760034345449       3   []    root   \n","\n","   runtime_seconds  \n","0           48.631  \n","1           45.294  \n","2           92.696  \n","3           44.382  \n","4           51.489  "],"text/html":["\n","  <div id=\"df-8ae7c438-d384-4372-a1a2-801c5f590af4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>experiment_id</th>\n","      <th>run_id</th>\n","      <th>artifact_uri</th>\n","      <th>end_time</th>\n","      <th>entry_point_name</th>\n","      <th>lifecycle_stage</th>\n","      <th>run_name</th>\n","      <th>source_name</th>\n","      <th>source_type</th>\n","      <th>source_version</th>\n","      <th>start_time</th>\n","      <th>status</th>\n","      <th>tags</th>\n","      <th>user_id</th>\n","      <th>runtime_seconds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>d800b7be6b1f452a91a148aa24791355</td>\n","      <td>file:///content/mlruns/0/d800b7be6b1f452a91a14...</td>\n","      <td>1760033890150</td>\n","      <td></td>\n","      <td>active</td>\n","      <td>Baseline-model_run1</td>\n","      <td></td>\n","      <td>4</td>\n","      <td></td>\n","      <td>1760033841519</td>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>root</td>\n","      <td>48.631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>73bb2b8f2771466abe54459d26ecbc33</td>\n","      <td>file:///content/mlruns/0/73bb2b8f2771466abe544...</td>\n","      <td>1760034750417</td>\n","      <td></td>\n","      <td>active</td>\n","      <td>PyDub-Whisper</td>\n","      <td></td>\n","      <td>4</td>\n","      <td></td>\n","      <td>1760034705123</td>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>root</td>\n","      <td>45.294</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>33514a226b13465ca6a0f8dd11fdb7b7</td>\n","      <td>file:///content/mlruns/0/33514a226b13465ca6a0f...</td>\n","      <td>1760035583964</td>\n","      <td></td>\n","      <td>active</td>\n","      <td>Using-faster-whisper</td>\n","      <td></td>\n","      <td>4</td>\n","      <td></td>\n","      <td>1760035491268</td>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>root</td>\n","      <td>92.696</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>089cee2123d142f998815b93c0d2fbe9</td>\n","      <td>file:///content/mlruns/0/089cee2123d142f998815...</td>\n","      <td>1760034580533</td>\n","      <td></td>\n","      <td>active</td>\n","      <td>Direct-Transcription</td>\n","      <td></td>\n","      <td>4</td>\n","      <td></td>\n","      <td>1760034536151</td>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>root</td>\n","      <td>44.382</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>68674e4a677e4243a1018d4029a26603</td>\n","      <td>file:///content/mlruns/0/68674e4a677e4243a1018...</td>\n","      <td>1760034396938</td>\n","      <td></td>\n","      <td>active</td>\n","      <td>UsingFFmpeg-Whisper1</td>\n","      <td></td>\n","      <td>4</td>\n","      <td></td>\n","      <td>1760034345449</td>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>root</td>\n","      <td>51.489</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ae7c438-d384-4372-a1a2-801c5f590af4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8ae7c438-d384-4372-a1a2-801c5f590af4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8ae7c438-d384-4372-a1a2-801c5f590af4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-844656cf-7c80-425a-b4d1-50194f4d772c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-844656cf-7c80-425a-b4d1-50194f4d772c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-844656cf-7c80-425a-b4d1-50194f4d772c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"parse_mlruns()\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"experiment_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"73bb2b8f2771466abe54459d26ecbc33\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"artifact_uri\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"file:///content/mlruns/0/73bb2b8f2771466abe54459d26ecbc33/artifacts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 618091,\n        \"min\": 1760033890150,\n        \"max\": 1760035583964,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1760034750417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entry_point_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lifecycle_stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"active\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"PyDub-Whisper\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_version\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 601722,\n        \"min\": 1760033841519,\n        \"max\": 1760035491268,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1760034705123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.430382064464677,\n        \"min\": 44.382,\n        \"max\": 92.696,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45.294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["data=parse_mlruns()"],"metadata":{"id":"-OZDy39ETxMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = data[['run_name', 'start_time','end_time', 'runtime_seconds']]"],"metadata":{"id":"psHivc1jTzKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The Compartion of different library for extracting the subtitle\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"hTUKXed8VbR1","executionInfo":{"status":"ok","timestamp":1760036489197,"user_tz":-330,"elapsed":56,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"4a8a0280-ffc0-49b2-db0a-016e99b78d6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               run_name     start_time       end_time  runtime_seconds\n","0   Baseline-model_run1  1760033841519  1760033890150           48.631\n","1         PyDub-Whisper  1760034705123  1760034750417           45.294\n","2  Using-faster-whisper  1760035491268  1760035583964           92.696\n","3  Direct-Transcription  1760034536151  1760034580533           44.382\n","4  UsingFFmpeg-Whisper1  1760034345449  1760034396938           51.489"],"text/html":["\n","  <div id=\"df-88dcbb58-9938-4ae1-8f08-baae7324abdd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>run_name</th>\n","      <th>start_time</th>\n","      <th>end_time</th>\n","      <th>runtime_seconds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Baseline-model_run1</td>\n","      <td>1760033841519</td>\n","      <td>1760033890150</td>\n","      <td>48.631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PyDub-Whisper</td>\n","      <td>1760034705123</td>\n","      <td>1760034750417</td>\n","      <td>45.294</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Using-faster-whisper</td>\n","      <td>1760035491268</td>\n","      <td>1760035583964</td>\n","      <td>92.696</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Direct-Transcription</td>\n","      <td>1760034536151</td>\n","      <td>1760034580533</td>\n","      <td>44.382</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>UsingFFmpeg-Whisper1</td>\n","      <td>1760034345449</td>\n","      <td>1760034396938</td>\n","      <td>51.489</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88dcbb58-9938-4ae1-8f08-baae7324abdd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-88dcbb58-9938-4ae1-8f08-baae7324abdd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-88dcbb58-9938-4ae1-8f08-baae7324abdd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bf9ef778-9ab8-4469-a999-07310c4e5a5c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf9ef778-9ab8-4469-a999-07310c4e5a5c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bf9ef778-9ab8-4469-a999-07310c4e5a5c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_3cb938e1-c396-4b37-8977-dece49c3e416\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3cb938e1-c396-4b37-8977-dece49c3e416 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"run_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"PyDub-Whisper\",\n          \"UsingFFmpeg-Whisper1\",\n          \"Using-faster-whisper\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 601722,\n        \"min\": 1760033841519,\n        \"max\": 1760035491268,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1760034705123,\n          1760034345449,\n          1760035491268\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 618091,\n        \"min\": 1760033890150,\n        \"max\": 1760035583964,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1760034750417,\n          1760034396938,\n          1760035583964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.430382064464677,\n        \"min\": 44.382,\n        \"max\": 92.696,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45.294,\n          51.489,\n          92.696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["## downloading the video\n","import shutil\n","from google.colab import files\n","\n","# Specify the folder you want to download\n","folder_to_download = '/content/mlruns'\n","\n","# Compress the folder into a .zip file\n","shutil.make_archive(folder_to_download, 'zip', folder_to_download)\n","\n","# Download the .zip file\n","files.download(f'{folder_to_download}.zip')\n"],"metadata":{"id":"Fp36s3egfQu_","executionInfo":{"status":"ok","timestamp":1760038842613,"user_tz":-330,"elapsed":64,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"76555817-a237-47cb-983d-5b11517ff9c9","colab":{"base_uri":"https://localhost:8080/","height":17}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7ef6c822-8803-4420-bf73-d62b116977a5\", \"mlruns.zip\", 12651)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### SceneDetection"],"metadata":{"id":"-AcEnP9gXgDn"}},{"cell_type":"code","source":["!pip install scenedetect\n","!pip install pytubefix"],"metadata":{"id":"3nkJVD0OVe45","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1760113660584,"user_tz":-330,"elapsed":22385,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"d78f19c3-1a02-49da-d9f4-86103a5f1f27"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scenedetect\n","  Downloading scenedetect-0.6.7.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting click<8.3.0,~=8.0 (from scenedetect)\n","  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scenedetect) (2.0.2)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scenedetect) (4.67.1)\n","Downloading scenedetect-0.6.7.1-py3-none-any.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: click, scenedetect\n","  Attempting uninstall: click\n","    Found existing installation: click 8.3.0\n","    Uninstalling click-8.3.0:\n","      Successfully uninstalled click-8.3.0\n","Successfully installed click-8.2.1 scenedetect-0.6.7.1\n","Collecting pytubefix\n","  Downloading pytubefix-10.0.0-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: aiohttp>=3.12.13 in /usr/local/lib/python3.12/dist-packages (from pytubefix) (3.12.15)\n","Collecting nodejs-wheel-binaries>=22.20.0 (from pytubefix)\n","  Downloading nodejs_wheel_binaries-22.20.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.20.1)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.12.13->pytubefix) (4.15.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.10)\n","Downloading pytubefix-10.0.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nodejs_wheel_binaries-22.20.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nodejs-wheel-binaries, pytubefix\n","Successfully installed nodejs-wheel-binaries-22.20.0 pytubefix-10.0.0\n"]}]},{"cell_type":"code","source":["# Library to import for the video download\n","from pytubefix import YouTube\n","from pytubefix.cli import on_progress\n","\n","#Library needed for the scenedetection\n","import scenedetect\n","from scenedetect import open_video\n","from scenedetect import detect, ContentDetector, split_video_ffmpeg\n"],"metadata":{"collapsed":true,"id":"TVXd0pUU0mD8","executionInfo":{"status":"ok","timestamp":1760119642249,"user_tz":-330,"elapsed":41,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def download_youtube_video(filename=\"Sample.mp4\"):\n","    try:\n","        #Asking for the url\n","        url=str(input(\"Enter the url of the video\"))\n","\n","        # Create a YouTube object\n","        yt = YouTube(url)\n","\n","        # Get the Video\n","        stream = yt.streams.filter(file_extension=\"mp4\", progressive=True).first()\n","\n","        # Download the video with a specific filename (if provided)\n","        if filename:\n","            downloaded_file = stream.download(filename=filename)\n","        else:\n","            downloaded_file = stream.download()\n","\n","        # Print the name of the downloaded file\n","        print(f\"Video downloaded successfully: {downloaded_file}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","    return downloaded_file"],"metadata":{"id":"DoerOrfb1HIe","executionInfo":{"status":"ok","timestamp":1760119643900,"user_tz":-330,"elapsed":46,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["x=download_youtube_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CY8btlgA1M8K","executionInfo":{"status":"ok","timestamp":1760119654219,"user_tz":-330,"elapsed":9045,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"75f1b9a4-80f1-4d19-cf8b-c2a452f715d5"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the url of the videohttps://youtu.be/eNvUS-6PTbs?si=3t22XDOqSqbuq5mJ\n","Video downloaded successfully: /content/Sample.mp4\n"]}]},{"cell_type":"code","source":["video=open_video(x)\n","while True:\n","  frame= video.read()\n","  if frame is False:\n","    break\n","print(\"Read %d frames\" % video.frame_number)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DntOqPG1dNX","executionInfo":{"status":"ok","timestamp":1760119660029,"user_tz":-330,"elapsed":3786,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"b3997754-1f05-4f0a-8cf4-7d4d3a4fbb41"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Read 4926 frames\n"]}]},{"cell_type":"code","source":["scenes=detect(x, ContentDetector())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbppsFvf1vec","executionInfo":{"status":"ok","timestamp":1760119672006,"user_tz":-330,"elapsed":10546,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"17d0474a-5dc4-47e3-ec2e-61cba94ccda9"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pyscenedetect:Detecting scenes...\n"]}]},{"cell_type":"code","source":["scenes=detect(x, ContentDetector())\n","data=[]\n","for (scene_start, scene_end) in scenes:\n","  data.append({\"Scence_start\":scene_start, \"Scence_end\":scene_end})\n","  print(f\"{scene_start}-{scene_end}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-48uSG3q15d3","executionInfo":{"status":"ok","timestamp":1760119687648,"user_tz":-330,"elapsed":10941,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"8c900baf-7099-4267-b925-f81ef2c14cba"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pyscenedetect:Detecting scenes...\n"]},{"output_type":"stream","name":"stdout","text":["00:00:00.000-00:00:01.840\n","00:00:01.840-00:00:03.120\n","00:00:03.120-00:00:06.120\n","00:00:06.120-00:00:08.200\n","00:00:08.200-00:00:15.360\n","00:00:15.360-00:00:16.680\n","00:00:16.680-00:00:18.200\n","00:00:18.200-00:00:30.360\n","00:00:30.360-00:00:42.840\n","00:00:42.840-00:00:44.840\n","00:00:44.840-00:00:46.840\n","00:00:46.840-00:00:48.920\n","00:00:48.920-00:00:49.920\n","00:00:49.920-00:00:50.960\n","00:00:50.960-00:00:58.560\n","00:00:58.560-00:00:59.840\n","00:00:59.840-00:01:01.640\n","00:01:01.640-00:01:05.760\n","00:01:05.760-00:01:07.760\n","00:01:07.760-00:01:10.000\n","00:01:10.000-00:01:12.000\n","00:01:12.000-00:01:16.120\n","00:01:16.120-00:01:17.040\n","00:01:17.040-00:01:18.680\n","00:01:18.680-00:01:28.120\n","00:01:28.120-00:01:35.840\n","00:01:35.840-00:01:43.440\n","00:01:43.440-00:01:44.680\n","00:01:44.680-00:01:51.640\n","00:01:51.640-00:01:59.400\n","00:01:59.400-00:02:34.360\n","00:02:34.360-00:02:40.640\n","00:02:40.640-00:02:43.360\n","00:02:43.360-00:02:48.120\n","00:02:48.120-00:02:49.120\n","00:02:49.120-00:02:56.120\n","00:02:56.120-00:02:56.840\n","00:02:56.840-00:02:59.760\n","00:02:59.760-00:03:16.400\n","00:03:16.400-00:03:17.040\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data1=pd.DataFrame(data)\n","data[1]"],"metadata":{"collapsed":true,"id":"zpcK1xv11_p8","executionInfo":{"status":"ok","timestamp":1760119710915,"user_tz":-330,"elapsed":18,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebce9e36-07af-485a-d373-c76bc7a0dbd7"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Scence_start': 00:00:01.840 [frame=46, fps=25.000],\n"," 'Scence_end': 00:00:03.120 [frame=78, fps=25.000]}"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["scenedetect.frame_timecode.FrameTimecode(timecode=3559, fps=46)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMaZ0VIZ3hiI","executionInfo":{"status":"ok","timestamp":1760114937007,"user_tz":-330,"elapsed":19,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"cfadeccb-177a-4b8d-eefd-24fbf98fdaa1"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["00:01:17.370 [frame=3559, fps=46.000]"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["### Merge Video"],"metadata":{"id":"iGIem8a7L_I5"}},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip, concatenate_videoclips\n","from scenedetect import FrameTimecode"],"metadata":{"collapsed":true,"id":"1BdWrlb46ttt","executionInfo":{"status":"ok","timestamp":1760119361505,"user_tz":-330,"elapsed":13,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["clip=VideoFileClip(x)\n","fps=25.0"],"metadata":{"id":"crwLeneg7IVP","executionInfo":{"status":"ok","timestamp":1760119569979,"user_tz":-330,"elapsed":98,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":[" scene=data[2]"],"metadata":{"id":"r-1fiFUDTC3j","executionInfo":{"status":"ok","timestamp":1760119716037,"user_tz":-330,"elapsed":21,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["for i in split_indices:\n","  print(data[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QypQOPukTAKB","executionInfo":{"status":"ok","timestamp":1760119735835,"user_tz":-330,"elapsed":63,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"35dbc6a3-988f-490d-d2fd-c28d35838c34"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Scence_start': 00:00:01.840 [frame=46, fps=25.000], 'Scence_end': 00:00:03.120 [frame=78, fps=25.000]}\n","{'Scence_start': 00:00:16.680 [frame=417, fps=25.000], 'Scence_end': 00:00:18.200 [frame=455, fps=25.000]}\n","{'Scence_start': 00:00:18.200 [frame=455, fps=25.000], 'Scence_end': 00:00:30.360 [frame=759, fps=25.000]}\n","{'Scence_start': 00:00:46.840 [frame=1171, fps=25.000], 'Scence_end': 00:00:48.920 [frame=1223, fps=25.000]}\n"]}]},{"cell_type":"code","source":["split_indices=[1,6, 7, 11]\n","split_clips=[]\n","clip=VideoFileClip(x)\n","\n","for i in split_indices:\n","  scene=data[i]\n","  start_tc=scene[\"Scence_start\"]\n","  end_tc=scene[\"Scence_end\"]\n","\n","  start_sec=start_tc.get_seconds()\n","  end_sec=end_tc.get_seconds()\n","  #mid_sec = start_sec + (end_sec - start_sec) / 2\n","\n","  split_clips.append(clip.subclip(start_sec, end_sec))\n","  \"\"\"    split_clips.append(clip.subclip(start_sec, mid_sec))\n","    split_clips.append(clip.subclip(mid_sec, end_sec))\"\"\"\n","\n","\n","final_clip=concatenate_videoclips(split_clips)\n","\n","for i in split_clips:\n","  final_clip=concatenate_videoclips([i])"],"metadata":{"collapsed":true,"id":"3I_oh5249PHo","executionInfo":{"status":"ok","timestamp":1760119744991,"user_tz":-330,"elapsed":1672,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["split_clips"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7Iy5h1jAySl","executionInfo":{"status":"ok","timestamp":1760115035800,"user_tz":-330,"elapsed":17,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"2eb58f76-fc41-4d67-8636-ee30f990c1d6"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<moviepy.video.io.VideoFileClip.VideoFileClip at 0x7abfc4b137d0>,\n"," <moviepy.video.io.VideoFileClip.VideoFileClip at 0x7abfc4b13500>,\n"," <moviepy.video.io.VideoFileClip.VideoFileClip at 0x7abfc4ac3530>,\n"," <moviepy.video.io.VideoFileClip.VideoFileClip at 0x7abfc4ac3b90>,\n"," <moviepy.video.io.VideoFileClip.VideoFileClip at 0x7abfc4ab8b00>]"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["final_clip = concatenate_videoclips(split_clips)\n","\n","# Export the result\n","final_clip.write_videofile(\"merged_video.mp4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWjGGwcX-V_e","executionInfo":{"status":"ok","timestamp":1760115045011,"user_tz":-330,"elapsed":8078,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"076678ca-a682-40b3-a7ee-4ab8d9adfaf6"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video merged_video.mp4.\n","MoviePy - Writing audio in merged_videoTEMP_MPY_wvf_snd.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video merged_video.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready merged_video.mp4\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"SXn5Y1WXLk2g","executionInfo":{"status":"ok","timestamp":1760117548821,"user_tz":-330,"elapsed":1027,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["x=download_youtube_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EXTSL-XK7DS","executionInfo":{"status":"ok","timestamp":1760118688400,"user_tz":-330,"elapsed":10763,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"b793e34d-f2fb-4dca-db27-984ee746557d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the url of the videohttps://youtu.be/eNvUS-6PTbs?si=Gwyn54cNEj8ytA3m\n","Video downloaded successfully: /content/Sample.mp4\n"]}]},{"cell_type":"code","source":["def scence_detected(path:str)-> str:\n","  scenes=detect(path, ContentDetector())\n","  data=[]\n","  for (scene_start, scene_end) in scenes:\n","    data.append({\"Scene_start\":scene_start, \"Scene_end\":scene_end})\n","  show_data=pd.DataFrame(data)\n","  return data, show_data"],"metadata":{"id":"m3B3U_9GJgda","executionInfo":{"status":"ok","timestamp":1760120461384,"user_tz":-330,"elapsed":20,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["data, show_data=scence_detected(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Bfe2rYn-P-QJ","executionInfo":{"status":"ok","timestamp":1760120478883,"user_tz":-330,"elapsed":11164,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"9b5c8719-3a30-42dd-8c1d-5f6fe25dcf86"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pyscenedetect:Detecting scenes...\n"]}]},{"cell_type":"code","source":["show_data.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eiU8oInTWyXW","executionInfo":{"status":"ok","timestamp":1760120491979,"user_tz":-330,"elapsed":108,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"cb407719-387c-4c69-a5b5-7c7754e216ce"},"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Scene_start     Scene_end\n","35  00:02:49.120  00:02:56.120\n","36  00:02:56.120  00:02:56.840\n","37  00:02:56.840  00:02:59.760\n","38  00:02:59.760  00:03:16.400\n","39  00:03:16.400  00:03:17.040"],"text/html":["\n","  <div id=\"df-fd5fb59c-9c7f-424f-8a7a-9267ff2f691b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Scene_start</th>\n","      <th>Scene_end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>35</th>\n","      <td>00:02:49.120</td>\n","      <td>00:02:56.120</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>00:02:56.120</td>\n","      <td>00:02:56.840</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>00:02:56.840</td>\n","      <td>00:02:59.760</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>00:02:59.760</td>\n","      <td>00:03:16.400</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>00:03:16.400</td>\n","      <td>00:03:17.040</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd5fb59c-9c7f-424f-8a7a-9267ff2f691b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fd5fb59c-9c7f-424f-8a7a-9267ff2f691b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fd5fb59c-9c7f-424f-8a7a-9267ff2f691b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-87543121-347c-46ed-a4fd-53f2dbf5086a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87543121-347c-46ed-a4fd-53f2dbf5086a')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-87543121-347c-46ed-a4fd-53f2dbf5086a button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"show_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Scene_start\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"00:02:56.120\",\n          \"00:03:16.400\",\n          \"00:02:56.840\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scene_end\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"00:02:56.840\",\n          \"00:03:17.040\",\n          \"00:02:59.760\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQd7QVnRV244","executionInfo":{"status":"ok","timestamp":1760120351478,"user_tz":-330,"elapsed":16,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"f7713cd6-588d-4d81-ae32-58d79ed784d4"},"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Scene_start': 00:00:00.000 [frame=0, fps=25.000],\n"," 'Scene_end': 00:00:01.840 [frame=46, fps=25.000]}"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["from typing import Dict, List\n","def merge_video(data=List[Dict],path=str,clip=list):\n","  \"\"\"\n","  data: The List of start and end point of scenedetection\n","  path: Path of the video\n","  clip[List]: The list of scene need to be merge\n","  \"\"\"\n","\n","  clip_path=VideoFileClip(path)\n","  split_clips=[]\n","\n","  for arg in clip:\n","    scene=data[arg]\n","    start_tc=scene[\"Scene_start\"]\n","    end_tc=scene[\"Scene_end\"]\n","\n","    start_sec=start_tc.get_seconds()\n","    end_sec=end_tc.get_seconds()\n","\n","    split_clips.append(clip_path.subclip(start_sec, end_sec))\n","\n","  final_clip=concatenate_videoclips(split_clips)\n","  final_clip.write_videofile(\"merge.mp4\")"],"metadata":{"id":"eloqoc3POiS3","executionInfo":{"status":"ok","timestamp":1760120709627,"user_tz":-330,"elapsed":38,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["list1=[2, 10, 16, 28]\n","result = [x - 1 for x in list1]\n"],"metadata":{"id":"4h8I2YrmSO1I","executionInfo":{"status":"ok","timestamp":1760120572292,"user_tz":-330,"elapsed":18,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"DD-EQNFRSZQl","executionInfo":{"status":"ok","timestamp":1760119331333,"user_tz":-330,"elapsed":34,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"1b16eed7-b0b3-4847-c9ae-b66737125a3e"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/Sample.mp4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["merge_video(data, x, result )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"d1vBGxaJOiP8","executionInfo":{"status":"ok","timestamp":1760120585811,"user_tz":-330,"elapsed":5818,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"733a52f4-f992-44d1-dec1-0ddbc45d74e0"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video merge.mp4.\n","MoviePy - Writing audio in mergeTEMP_MPY_wvf_snd.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video merge.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready merge.mp4\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gxhNhMtzOiFO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Looking the video"],"metadata":{"id":"6jBpTnFF_Zx1"}},{"cell_type":"code","source":["from IPython.display import Video"],"metadata":{"id":"It4BjwgI_KpA","executionInfo":{"status":"ok","timestamp":1760118213275,"user_tz":-330,"elapsed":26,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from IPython.display import HTML"],"metadata":{"id":"atYFPAs6-cUB","executionInfo":{"status":"ok","timestamp":1760114180988,"user_tz":-330,"elapsed":8,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["Video('/content/Sample.mp4')"],"metadata":{"colab":{"resources":{"http://localhost:8080/content/Sample.mp4":{"data":"","ok":false,"headers":[["content-length","0"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":172},"id":"s13uAaVr-wIi","executionInfo":{"status":"ok","timestamp":1760118244485,"user_tz":-330,"elapsed":21,"user":{"displayName":"anith prakashan","userId":"10213607084400107118"}},"outputId":"8e9806e0-b88e-4be3-88c6-933cfc331b97"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"/content/Sample.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"FLFsYcUZOLH6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Find the main part of the video"],"metadata":{"id":"szCyZbKvYMyW"}},{"cell_type":"markdown","source":["DEEP DIVE BRUH!!!"],"metadata":{"id":"ALWdRLquYNsu"}},{"cell_type":"code","source":[],"metadata":{"id":"97Hgh4GTYdBQ"},"execution_count":null,"outputs":[]}]}